{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AULA 1 - NUMPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Selecione todos os valores ímpares do seguinte array:  <br>\n",
    "array = [1, 2, 3, 4, 5, 6, 7, 8, 9] <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 5, 7, 9])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.array([1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "filtro = array % 2 == 1\n",
    "impares = array[filtro]\n",
    "impares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Substitua os valores ímpares do seguinte array por 0:  <br>\n",
    "array = [1, 2, 3, 4, 5, 6, 7, 8, 9] <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 4, 0, 6, 0, 8, 0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_v2 = array.copy()\n",
    "\n",
    "array_v2[filtro] = 0\n",
    "array_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Considere o dataset da iris disponível em: \n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'<br> \n",
    "Nesse dataset temos as seguintes informações:<br> \n",
    "   * Coluna 1. sepal length em cm<br> \n",
    "   * Coluna 2. sepal width em cm<br> \n",
    "   * Coluna 3. petal length em cm<br> \n",
    "   * Coluna 4. petal width em cm<br> \n",
    "   * Coluna 5. classe: \n",
    "                -- Iris Setosa \n",
    "                -- Iris Versicolour \n",
    "                -- Iris Virginica \n",
    "                \n",
    "Utilizando o método `np.genfromtxt()`, importe as 4 primeiras colunas do dataset do íris e print as 10 primeiras linhas <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "iris = np.genfromtxt(url, delimiter = ',', dtype = 'float', usecols = [0,1,2,3])\n",
    "nomes = ('sepallength', 'sepalwidth', 'petallength', 'petalwidth', 'species')\n",
    "\n",
    "iris[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Calcule a média, mediana e desvio padrão da coluna sepallenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.843333333333334, 5.8, 0.8253012917851409)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepalLength = iris[:,0]\n",
    "\n",
    "media =  np.mean(sepalLength)\n",
    "mediana = np.median(sepalLength)\n",
    "desvio = np.std(sepalLength)\n",
    "\n",
    "media, mediana, desvio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - Filtre a matriz para conter apenas dados nos quais petallength (3ª coluna) > 1.5 e sepallength (1ª coluna) < 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [4.9, 2.5, 4.5, 1.7]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtro = (iris[:,2] > 1.5) & (iris[:,0] < 5.0)\n",
    "iris[filtro]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 - Esse dataset possui nans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(iris).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 - Crie uma coluna de volume sabendo que ele pode ser calculado por (pi x petallength x sepal_length^2)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.10, 3.50, 1.40, 0.20, 38.13],\n",
       "       [4.90, 3.00, 1.40, 0.20, 35.20],\n",
       "       [4.70, 3.20, 1.30, 0.20, 30.07],\n",
       "       [4.60, 3.10, 1.50, 0.20, 33.24],\n",
       "       [5.00, 3.60, 1.40, 0.20, 36.65],\n",
       "       [5.40, 3.90, 1.70, 0.40, 51.91],\n",
       "       [4.60, 3.40, 1.40, 0.30, 31.02],\n",
       "       [5.00, 3.40, 1.50, 0.20, 39.27],\n",
       "       [4.40, 2.90, 1.40, 0.20, 28.38],\n",
       "       [4.90, 3.10, 1.50, 0.10, 37.71],\n",
       "       [5.40, 3.70, 1.50, 0.20, 45.80],\n",
       "       [4.80, 3.40, 1.60, 0.20, 38.60],\n",
       "       [4.80, 3.00, 1.40, 0.10, 33.78],\n",
       "       [4.30, 3.00, 1.10, 0.10, 21.30],\n",
       "       [5.80, 4.00, 1.20, 0.20, 42.27],\n",
       "       [5.70, 4.40, 1.50, 0.40, 51.04],\n",
       "       [5.40, 3.90, 1.30, 0.40, 39.70],\n",
       "       [5.10, 3.50, 1.40, 0.30, 38.13],\n",
       "       [5.70, 3.80, 1.70, 0.30, 57.84],\n",
       "       [5.10, 3.80, 1.50, 0.30, 40.86],\n",
       "       [5.40, 3.40, 1.70, 0.20, 51.91],\n",
       "       [5.10, 3.70, 1.50, 0.40, 40.86],\n",
       "       [4.60, 3.60, 1.00, 0.20, 22.16],\n",
       "       [5.10, 3.30, 1.70, 0.50, 46.30],\n",
       "       [4.80, 3.40, 1.90, 0.20, 45.84],\n",
       "       [5.00, 3.00, 1.60, 0.20, 41.89],\n",
       "       [5.00, 3.40, 1.60, 0.40, 41.89],\n",
       "       [5.20, 3.50, 1.50, 0.20, 42.47],\n",
       "       [5.20, 3.40, 1.40, 0.20, 39.64],\n",
       "       [4.70, 3.20, 1.60, 0.20, 37.01],\n",
       "       [4.80, 3.10, 1.60, 0.20, 38.60],\n",
       "       [5.40, 3.40, 1.50, 0.40, 45.80],\n",
       "       [5.20, 4.10, 1.50, 0.10, 42.47],\n",
       "       [5.50, 4.20, 1.40, 0.20, 44.35],\n",
       "       [4.90, 3.10, 1.50, 0.10, 37.71],\n",
       "       [5.00, 3.20, 1.20, 0.20, 31.42],\n",
       "       [5.50, 3.50, 1.30, 0.20, 41.18],\n",
       "       [4.90, 3.10, 1.50, 0.10, 37.71],\n",
       "       [4.40, 3.00, 1.30, 0.20, 26.36],\n",
       "       [5.10, 3.40, 1.50, 0.20, 40.86],\n",
       "       [5.00, 3.50, 1.30, 0.30, 34.03],\n",
       "       [4.50, 2.30, 1.30, 0.30, 27.57],\n",
       "       [4.40, 3.20, 1.30, 0.20, 26.36],\n",
       "       [5.00, 3.50, 1.60, 0.60, 41.89],\n",
       "       [5.10, 3.80, 1.90, 0.40, 51.75],\n",
       "       [4.80, 3.00, 1.40, 0.30, 33.78],\n",
       "       [5.10, 3.80, 1.60, 0.20, 43.58],\n",
       "       [4.60, 3.20, 1.40, 0.20, 31.02],\n",
       "       [5.30, 3.70, 1.50, 0.20, 44.12],\n",
       "       [5.00, 3.30, 1.40, 0.20, 36.65],\n",
       "       [7.00, 3.20, 4.70, 1.40, 241.17],\n",
       "       [6.40, 3.20, 4.50, 1.50, 193.02],\n",
       "       [6.90, 3.10, 4.90, 1.50, 244.30],\n",
       "       [5.50, 2.30, 4.00, 1.30, 126.71],\n",
       "       [6.50, 2.80, 4.60, 1.50, 203.52],\n",
       "       [5.70, 2.80, 4.50, 1.30, 153.11],\n",
       "       [6.30, 3.30, 4.70, 1.60, 195.35],\n",
       "       [4.90, 2.40, 3.30, 1.00, 82.97],\n",
       "       [6.60, 2.90, 4.60, 1.30, 209.83],\n",
       "       [5.20, 2.70, 3.90, 1.40, 110.43],\n",
       "       [5.00, 2.00, 3.50, 1.00, 91.63],\n",
       "       [5.90, 3.00, 4.20, 1.50, 153.10],\n",
       "       [6.00, 2.20, 4.00, 1.00, 150.80],\n",
       "       [6.10, 2.90, 4.70, 1.40, 183.14],\n",
       "       [5.60, 2.90, 3.60, 1.30, 118.22],\n",
       "       [6.70, 3.10, 4.40, 1.40, 206.84],\n",
       "       [5.60, 3.00, 4.50, 1.50, 147.78],\n",
       "       [5.80, 2.70, 4.10, 1.00, 144.43],\n",
       "       [6.20, 2.20, 4.50, 1.50, 181.14],\n",
       "       [5.60, 2.50, 3.90, 1.10, 128.08],\n",
       "       [5.90, 3.20, 4.80, 1.80, 174.97],\n",
       "       [6.10, 2.80, 4.00, 1.30, 155.86],\n",
       "       [6.30, 2.50, 4.90, 1.50, 203.66],\n",
       "       [6.10, 2.80, 4.70, 1.20, 183.14],\n",
       "       [6.40, 2.90, 4.30, 1.30, 184.44],\n",
       "       [6.60, 3.00, 4.40, 1.40, 200.71],\n",
       "       [6.80, 2.80, 4.80, 1.40, 232.43],\n",
       "       [6.70, 3.00, 5.00, 1.70, 235.04],\n",
       "       [6.00, 2.90, 4.50, 1.50, 169.65],\n",
       "       [5.70, 2.60, 3.50, 1.00, 119.08],\n",
       "       [5.50, 2.40, 3.80, 1.10, 120.38],\n",
       "       [5.50, 2.40, 3.70, 1.00, 117.21],\n",
       "       [5.80, 2.70, 3.90, 1.20, 137.39],\n",
       "       [6.00, 2.70, 5.10, 1.60, 192.27],\n",
       "       [5.40, 3.00, 4.50, 1.50, 137.41],\n",
       "       [6.00, 3.40, 4.50, 1.60, 169.65],\n",
       "       [6.70, 3.10, 4.70, 1.50, 220.94],\n",
       "       [6.30, 2.30, 4.40, 1.30, 182.88],\n",
       "       [5.60, 3.00, 4.10, 1.30, 134.64],\n",
       "       [5.50, 2.50, 4.00, 1.30, 126.71],\n",
       "       [5.50, 2.60, 4.40, 1.20, 139.38],\n",
       "       [6.10, 3.00, 4.60, 1.40, 179.24],\n",
       "       [5.80, 2.60, 4.00, 1.20, 140.91],\n",
       "       [5.00, 2.30, 3.30, 1.00, 86.39],\n",
       "       [5.60, 2.70, 4.20, 1.30, 137.93],\n",
       "       [5.70, 3.00, 4.20, 1.20, 142.90],\n",
       "       [5.70, 2.90, 4.20, 1.30, 142.90],\n",
       "       [6.20, 2.90, 4.30, 1.30, 173.09],\n",
       "       [5.10, 2.50, 3.00, 1.10, 81.71],\n",
       "       [5.70, 2.80, 4.10, 1.30, 139.50],\n",
       "       [6.30, 3.30, 6.00, 2.50, 249.38],\n",
       "       [5.80, 2.70, 5.10, 1.90, 179.66],\n",
       "       [7.10, 3.00, 5.90, 2.10, 311.46],\n",
       "       [6.30, 2.90, 5.60, 1.80, 232.75],\n",
       "       [6.50, 3.00, 5.80, 2.20, 256.62],\n",
       "       [7.60, 3.00, 6.60, 2.10, 399.21],\n",
       "       [4.90, 2.50, 4.50, 1.70, 113.14],\n",
       "       [7.30, 2.90, 6.30, 1.80, 351.57],\n",
       "       [6.70, 2.50, 5.80, 1.80, 272.65],\n",
       "       [7.20, 3.60, 6.10, 2.50, 331.15],\n",
       "       [6.50, 3.20, 5.10, 2.00, 225.64],\n",
       "       [6.40, 2.70, 5.30, 1.90, 227.33],\n",
       "       [6.80, 3.00, 5.50, 2.10, 266.32],\n",
       "       [5.70, 2.50, 5.00, 2.00, 170.12],\n",
       "       [5.80, 2.80, 5.10, 2.40, 179.66],\n",
       "       [6.40, 3.20, 5.30, 2.30, 227.33],\n",
       "       [6.50, 3.00, 5.50, 1.80, 243.34],\n",
       "       [7.70, 3.80, 6.70, 2.20, 415.99],\n",
       "       [7.70, 2.60, 6.90, 2.30, 428.41],\n",
       "       [6.00, 2.20, 5.00, 1.50, 188.50],\n",
       "       [6.90, 3.20, 5.70, 2.30, 284.19],\n",
       "       [5.60, 2.80, 4.90, 2.00, 160.92],\n",
       "       [7.70, 2.80, 6.70, 2.00, 415.99],\n",
       "       [6.30, 2.70, 4.90, 1.80, 203.66],\n",
       "       [6.70, 3.30, 5.70, 2.10, 267.95],\n",
       "       [7.20, 3.20, 6.00, 1.80, 325.72],\n",
       "       [6.20, 2.80, 4.80, 1.80, 193.22],\n",
       "       [6.10, 3.00, 4.90, 1.80, 190.93],\n",
       "       [6.40, 2.80, 5.60, 2.10, 240.20],\n",
       "       [7.20, 3.00, 5.80, 1.60, 314.86],\n",
       "       [7.40, 2.80, 6.10, 1.90, 349.80],\n",
       "       [7.90, 3.80, 6.40, 2.00, 418.28],\n",
       "       [6.40, 2.80, 5.60, 2.20, 240.20],\n",
       "       [6.30, 2.80, 5.10, 1.50, 211.97],\n",
       "       [6.10, 2.60, 5.60, 1.40, 218.21],\n",
       "       [7.70, 3.00, 6.10, 2.30, 378.74],\n",
       "       [6.30, 3.40, 5.60, 2.40, 232.75],\n",
       "       [6.40, 3.10, 5.50, 1.80, 235.91],\n",
       "       [6.00, 3.00, 4.80, 1.80, 180.96],\n",
       "       [6.90, 3.10, 5.40, 2.10, 269.23],\n",
       "       [6.70, 3.10, 5.60, 2.40, 263.25],\n",
       "       [6.90, 3.10, 5.10, 2.30, 254.27],\n",
       "       [5.80, 2.70, 5.10, 1.90, 179.66],\n",
       "       [6.80, 3.20, 5.90, 2.30, 285.69],\n",
       "       [6.70, 3.30, 5.70, 2.50, 267.95],\n",
       "       [6.70, 3.00, 5.20, 2.30, 244.45],\n",
       "       [6.30, 2.50, 5.00, 1.90, 207.82],\n",
       "       [6.50, 3.00, 5.20, 2.00, 230.07],\n",
       "       [6.20, 3.40, 5.40, 2.30, 217.37],\n",
       "       [5.90, 3.00, 5.10, 1.80, 185.91]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume = (np.pi * iris[:,2] * iris[:,0]**2)/3\n",
    "volume2decimal = np.around(volume,decimals=2)\n",
    "irisVolume = np.c_[ iris, volume2decimal ]\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})\n",
    "irisVolume"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
